
\chapter{Editor}
 
By using our custom made editor, the user will be able to design and control a layout for any type of graphical effect or behavior. The editor will be able to load and store these designs directly from within the editor and distribute them to other users of this product, or preview them using the rendering backend. 
Each component’s behavior is described by scripts, interpreted on run-time by the engine. This feature adds to the extendability of the program. New components does not need to be compiled within the binary and can be designed and written by anyone with a basic understanding of programming.
In large projects when the workspace gets cluttered from wires and boxes, a user can batch components together in groups. These groups can then be minimized or collapsed in order to achieve a better overview of the project. This functionality also serves as a performance increase, as each component and wire require processing power to visualize. 
The editor supports simple user interaction via either keyboard or mouse input; the user can manipulate component properties and preview results of either each individual output channel, component group channels or the final output of the pipeline. Since the rendering is decoupled, a user can create individual effect chains and distribute these over different servers without severe performance decrease. 

\section{Editor Core}
To enable us to have greatest possible freedom when creating the pipeline components later on, in regards to look and functionality, we decided to create our own GUI system for the editor. This however meant that we would have to recreate standard GUI widgets such as labels, text boxes and buttons. To accomplish this we decided to create our own GUI backend, where all GUI components where scriptable and modifiable at runtime.

\subsection{Application and GUI Backend}
The application backend is designed in such way that it will have little to none impact on the editor functionality and look. Instead it act more as a generic application providing drawing and input functionality via scripting, where its final functionality and look can be scripted and changed/updated at runtime. This enable us to develop the editor without having to recompile the main application every time a change is made. The application backend thus don't have any ready built GUI functions on it's own, they are instead implemented via external scripts. To keep platform independence we use OpenGL for all rendering purposes and window handling. The scripting language chosen was Lua, due to its ease of use and widespread use in the gaming industry.

The focus of the backend itself was providing input/output for the scripts in intuitively way, without loosing efficiency and speed. For example are all drawing calls cached, and only executed/rendered when explicitly needed. It's is up to the user to specify the whole window or only a part of it, when and where rendering is needed, and thus hopefully limiting the amount of fill needed to update the window. This is accomplished inside the backend by using the stencil buffer as a mask to specify regions where to draw.

All input functionality (ie. mouse and keyboard input) are done by exposing functions from the input managing component of GLFW.

\subsection{Application Scripts}
An application script that uses our application backend only need to implement two major functions to run.
\pic[0.7]{img/application_scripts.png}{Application script body.}
\begin{enumerate}
  \item \texttt{draw()} will be called when the application needs to redraw itself, in most cases when the script itself notifies the backend using the function \texttt{needsredraw()}.
  \item \texttt{update()} is called 60 times per second, and is where the application script should do most of it's processing.
\end{enumerate}

\subsection{GUI Scripts}
We implemented a basic GUI system that was able to handle all our needs. The system is design as a tree structure of GUI widgets, where the root widget is the screen/view area itself.
\pic[0.7]{img/gui_system.png}{Layout of GUI system.}
\begin{enumerate}
  \item \texttt{gui:init()} has to be called to initiate the GUI system.
  \item \texttt{gui:draw()} should be called when we want to redraw the GUI. It's up to the GUI system to keep track of which widgets need to redraw.
  \item \texttt{gui:update()} should be called when we want to update the GUI. This is where mouse and keyboard inputs are handled for the GUI, and thus should be called as often as possible (preferably inside the applications \texttt{update()} function), to avoid missing any input events.
  \item \texttt{gui.widgets} is the tree of GUI widgets, i.e. the root widget instance. Any new widget added to the GUI has to be added to this one.
\end{enumerate}

\pic[0.7]{img/gui_widgets.png}{Core components of a GUI widget.}
\begin{enumerate}
  \item \texttt{widget:draw()} will be called when the GUI system needs to redraw a specific widget. This in turn calls the \texttt{draw()} function on all the child widgets.
  \item \texttt{widget:update()} is called every time the GUI system is updated (i.e. via the \texttt{gui:update()} is run). (This in turn calls the \texttt{update()} function on all the child widgets.)
  \item \texttt{widget:addwidget(new\_child)} is used to add a new child widget to this widget in the tree.
  \item \texttt{widget.childwidgets} a list of GUI widgets that act as childs to this one. If the widget don't have any child, it will be a leaf node in the GUI tree.
  \item \texttt{widget.hitbox} a set of coordinates and dimensions of where the widget are active and should take care of mouse inputs. (The coordinates are relative to the widgets parent.)
  \item \texttt{widget.drawbox} a set of coordinates and dimensions of where the widget has its active draw area (i.e. where it is allowed to draw during the \texttt{widget:draw()} function).
\end{enumerate}

The editor is built entierly by scripts, programmed in LUA. AOEOEOEOE

-- Tree structure


-- 

Every widget type is derived from a single basic widget table, with several basic functions for drawing,hittesting,attaching/detaching widgets etc. Due to the architechture of LUA, each of these functions are seen as virtual functions and can thus easily be overwritten to enable a specific behaviour. For example, the basic draw function simply calls draw on each of the widgets attached to that widget, and nothing else. In most cases, the user might want specific graphics and can simply do so by overshadowing the draw function of the widget in the script. 

\subsection{Component Graph}
The user constructs the rendering pipeline by using a component graph. A component is a black box that performs transformations on geometry and pixel fragments, displayed as GUI widgets that contains data inputs/outputs and various properties and settings for the component itself. The user connects the component’s input and output channels together in order to create the data flow of the pipeline. 

Each component contains a table of JSON data that describes the behaviour of that specific component, by meta-data and raw shader code that is ultimately used to render the outcome of the component as a texture. The render server sends this texture for each individual pass back to the editor, together with timing information for said pass. This enables the user to view the result of each component in 

The components are divided into four basic subclasses: Render, Auxiliary, Post-Process and Output respectively. Each category 
gives the user an indication of the functionality of said subclass. 

Render block
The render block contains information and data to control a 3D scene and currently comes in two flavors, blinn-phong and advanced. The blinn-phong render block requires atleast 6 standard inputs in order to render properly: Camera Position, Camera Lookat, Light Position, Light Color, Model and Texture, where the last two inputs must be that of the Texture/Model auxiliary compoent blocks. The other four can, as with any component block, need only numeric values and can thus be connected by script blocks, static numeric blocks or basically anything that yields data in vec3 form. For example, the camera position can be designed to follow a certain node-path calculated by a spline algorithm, built in a lua script. 

The advanced render block is a further expansion upon the blinn-phong render block, which enables the user to access diffuse,depth  and normal values in separate texture channels from the component block. These texture channels can then be connected individually to other parts of the component graph. 

Layout/Design
The basic layout of the editor is divided in four parts/areas, each which provides specific functionality to the user. 

[ lägga till någon "future versions" eller liknande?]
Originially, it was intended to include user custom color schemes, manipulated by a hue-shift shader. The purpose of which is to enable users to customize the look of the whole editor to better suit the users needs, such as light-dark contrast as well as general color preference. This idea is a common element in various modern visual editors, but will be implemented in a further version. 

Workspace
The workspace is the central area of the editor. This is where the user creates, and otherwise manipulate the components and their connections. The user selects and adds components from a list of sub-classes from a drop-down menu, accessible by right-cllicking the workspace area. 

Several workspace layouts can be loaded in memory simultaniously, wich enables users to test several concepts at once, against servers with different hardware capabilities, for example. (Note, this is currently disabled as it was added quite late in the project, and is therefore not entierly bug-free.)

Menu

Inspector
The inspector is used to display various information about a selected component, and is spawned and attached as a widget on to the inspector panel. What information to display is up to the component designer to decide, and is thus constituted by whatever the programmer finds intuitive to the user to know. Currently, the inspector is used to display the result of the selected component, as well as timing information from the render pass.

Toolbar
The toolbar contains a set of tools that manipulate the workspace. Currently, six basic tools are implemented: Undo,Redo,Move Workspace, Move Select, Rectangular Move and Delete component. However a small set, due to the flexible design of the editor, tools can easily be designed and added to the toolbar with little effort. 
 