\chapter{Description}
%Dealing with large quantities of computational data is an ever current topic, not only in Computer Science but in various other scientific %areas aswell. Even though new and faster microprocessors reduce computational cost linearly, parallelism (where applicable) over large %problem sets yields even higher speedup gains. 

% - Speed-sensitivity
% - Old problem but new technology / techniques (p2p)
% - Combination of interesting areas?
% - Generic approach, but with specific implementation
% - Academic study of relationship between network distribution cost vs. running on one computer?  

The idea of this project is to build a two-part prototype, capable of distributing computational data over a peer-to-peer (P2P) network, and retrieving the results within a feasible time frame. The first part deals with communication between remote clients in a decentralized network, with focus on fast data transfer rather than handling large amounts of data. The protocol will primarily be used to synchronize clients in the network to collectively share the computational workload of a task. 

The second part of the project consists of a na√Øve ray tracer that can subdivide a scene into smaller jobs (for example screen regions / blocks), and then process them with little to none dependence on each other or the rest of the scene. Each job is automatically distributed over the network, and the results should be sent back to the job initiator as soon each job finishes.

The general purpose of this project is to examine if distributed ray tracing calculations, over a P2P network, is able to reduce the render time of an arbitrarily complex 3D scene, compared to a regular local ray tracing solution. Implementing a new ray tracing application gives a deeper knowledge on ray tracing as a topic but also a greater freedom when incorporating it into the rest of the project, compared to existing ray tracing solutions.

